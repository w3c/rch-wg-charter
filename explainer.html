<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <title>Linked Data Signatures Working Group Charter—Explainer</title>
  <script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer></script>
  <script class="remove">
// All config options at https://respec.org/docs/
var respecConfig = {
  specStatus: "base",
  editors: [{
    name: "Ivan Herman",
    url: "https://www.w3.org/People/Ivan/",
    company: "W3C",
    w3cid: 7382,
    orcid: "0000-0003-0782-2704",
    companyURL: "https://www.w3.org",
  }],
  authors: [{
    name: "Ivan Herman",
    url: "https://www.w3.org/People/Ivan/",
    company: "W3C",
    w3cid: 7382,
    orcid: "0000-0003-0782-2704",
    companyURL: "https://www.w3.org",
  }, {
    name: "Manu Sporny",
    url: "http://manu.sporny.org/",
    company: "Digital Bazaar",
    companyURL: "https://digitalbazaar.com/",
    w3cid: 41758
  }, {
    name: "Alan Karp",
    url: "https://alanhkarp.com/",
    company: "Earth Computing",
    companyURL: "https://www.earthcomputing.io/",
  }],
  github: "iherman/ld-signatures-charter",
  localBiblio: {
    "aidan-2017" : {
      title: "Canonical Forms for Isomorphic and Equivalent RDF Graphs: Algorithms for Leaning and Labelling Blank Nodes",
      authors: [
        "Aidan Hogan"
      ],
      href : "http://aidanhogan.com/docs/rdf-canonicalisation.pdf",
      publisher: "ACM Transactions on the Web",
      date : 2017
    },
    "rdf-dataset-normalization": {
      title: "RDF Dataset Normalization",
      editors : [
        "Dave Longley",
        "Manu Sporny"
      ],
      href: "https://json-ld.github.io/normalization/spec/index.html",
      publisher: "W3C",
      status: "W3C Community Group Report",
      date : 2021
    }
  }
};
  </script>
  <style>
.issue {
  background: teal !important;
  color: #FFC !important ;
}

.issue::before {
  content: "\2009";
}

.issue::after {
  content: "\2009";
}

.todo {
  color: #900 !important;
  background-color: #FFC !important;
}

.rdf {
  font-style: italic;
  font-family: cursive;
}
  </style>
</head>

<body>
  <section id="abstract">
    <p>
This is a supporting document for the proposed <a href="index.html">Linked Data
Signatures Working Group Charter</a>, providing some extra explanation of
the problem space and associated use cases and requirements.
    </p>
  </section>

  <section id='canonicalize'>
    <h2>Terminology</h2>

    <p>
For a precise definition for the various terms and notions, the reader should
refer to the formal RDF specification [[rdf11-concepts]]. Note also that the
term “Linked Data” is used as a synonym to “RDF Datasets”.
    </p>

    <dl>
      <dt id='dataset'>RDF Datasets</dt>
      <dd>
        <p>
<span class='rdf'>R</span>, <span class='rdf'>S</span>,&nbsp; etc., denote an <a
href="https://www.w3.org/TR/rdf11-concepts/#section-dataset">RDF Dataset</a>
[[rdf11-concepts]].
        </p>
        <p>
The term “named graphs” is also used in literature or in applications.
        </p>
      </dd>

      <dt id='identical'>Identical RDF Datasets</dt>
      <dd>
        <p>
<span class='rdf'>R = S</span> denotes two <em>identical</em> RDF Datasets.
        </p>
        <p>
Identical RDF Datasets consists of the same <a
href="https://www.w3.org/TR/rdf11-concepts/#section-rdf-graph">RDF Graphs</a>
(where “the same” means they are the same set of triples) with the same <a
href="https://www.w3.org/TR/rdf11-concepts/#section-dataset">Graph Names</a>.
        </p>
      </dd>

      <dt id='isomorphic'>Isomorphic RDF Datasets</dt>
      <dd>
        <p>
<span class='rdf'>R ≈ S</span> denotes two <a
href='https://www.w3.org/TR/rdf11-concepts/#section-dataset-isomorphism'><em>isomorphic</em></a>
RDF Datasets.
        </p>
        <p>
The structure of two isomorphic Datasets are identical: URIs and literals are
all character-wise identical, and it is possible to relabel the blank nodes of
<span class='rdf'>R</span> to the blank nodes of <span class='rdf'>S</span>
without changing the topology of the graph.
        </p>
      </dd>

      <dt id="canonical_form">Canonical Form</dt>
      <dd>
        <p>
For an RDF Dataset <span class='rdf'>R</span>, a <em>canonical form</em> of
<span class='rdf'>R</span> is a dataset <span class='rdf'>R<sub>C</sub></span>
such that <span class='rdf'>R<sub>C</sub> = S<sub>C</sub></span> if and only if
<span class='rdf'>R ≈ S</span>.
        </p>
      </dd>

      <dt id='canonicalization'>Canonicalization</dt>
      <dd>
        <p>
Canonicalization is a function <span class='rdf'>C</span> on RDF Datasets such
that <span class='rdf'>C(R)</span> is a Canonical Form for <span
class='rdf'>R</span>.
        </p>
        <p>
Definition of a canonicalization function means, in practice, to define a
deterministic re-labeling procedure of all blank nodes of an RDF Dataset without
changing the topology of the graph, and whose result is not dependent on the
particular set of blank node labels used in the Dataset.
        </p>
      </dd>

      <dt id='ld-hash'>RDF Dataset Hash (or Linked Data Hash)</dt>
      <dd>
        <p>
A <a href="https://en.wikipedia.org/wiki/Hash_function">hash function</a> <span
class='rdf'>h</span> defined on RDF Datasets which has the additional property
that for any RDF Datasets <span class='rdf'>R</span> and <span
class='rdf'>S</span>, the relation <span class='rdf'>R&nbsp;≈&nbsp;S</span>
implies <span class='rdf'>h(R)&nbsp;=&nbsp;h(S)</span>.
        </p>

      </dd>
    </dl>

    <section>
      <h2>The General Problem Space</h2>
      <p>
Defining a generalized canonicalization function was an unsolved mathematical
problem until the last decade. Over the past 10 years, at least two generalized
approaches have been proposed:
      </p>

      <ol>
        <li>
The algorithms defined Aidan Hogan in [[aidan-2017]], reviewed through the
scholarly peer review process.
        </li>
        <li>
The algorithm defined and implemented Dave Longley, see
[[rdf-dataset-normalization]]. <span class=issue>we will need references to the
algorithmic description and the referees reviews</span>
        </li>
      </ol>

      <p>
The introduction of <a
href="http://aidanhogan.com/docs/rdf-canonicalisation.pdf">Adrian Hogan’s
paper</a>&nbsp;[[aidan-2017]] also contains a more thorough description of the
underlying mathematical challenges.
      </p>
    </section>
  </section>

  <section id=goals>
    <h2>Defining an RDF Dataset Hash and/or Signing RDF Datasets</h2>

    <p>
Signing an RDF Dataset follows, roughly, the same approach as for
XML&nbsp;[[xmldsig-core1]]. For an RDF Dataset <span class='rdf'>R</span> this
implies two steps:
    </p>

    <ol id=sign>
      <li>
use an <a href="#ld-hash">RDF Dataset Hash function</a> <span
class='rdf'>h</span> to calculate <span class='rdf'>h(R)</span>;
      </li>
      <li>
apply a digital signature function on <span class='rdf'>h(R)</span>.
      </li>
    </ol>

    <p>
Whereas step (2) may rely on well documented methods, standards, and libraries
developed by the cryptography community, step (1) requires more complex steps:
    </p>

    <ol id=hash type="i">
      <li>
use an <a href="#canonicalization">RDF Dataset Canonicalization function</a>
<span class='rdf'>C</span>&nbsp; to generate the canonical form <span
class='rdf'>C(R)</span>;
      </li>

      <li>
serialize <span class='rdf'>C(R)</span> to quads&nbsp;[[n-quads]] and sort the
resulting set of quads;
      </li>

      <li>
apply a (traditional) hashing function <span class='rdf'>H</span> on the result
of the serialization to yield <span class='rdf'>h(R)</span>.
      </li>
    </ol>

    <p>
The main challenge for the Working Group is to provide a standard for the <a
href="#canonicalization">RDF Dataset Canonicalization function</a>. That paves
the way for defining RDF Dataset Hash functions, as well as methods to sign RDF
Datasets.
    </p>
  </section>

  <section id=usage>
    <h2>Use Cases and Requirements</h2>

    <p>
Some typical use cases for RDF Dataset Canonicalization and/or signatures are:
    </p>

    <dl>
      <dt>Detecting changes in Datasets</dt>
      <dd>
When processing RDF Datasets over a period of time, determining if information
has changed is helpful. For example, knowing if information has changed helps
with data cache invalidation, detecting if expected data has been tampered with
or modified, or when debugging unexpected changes in source RDF Datasets.
Requirement: An RDF Dataset Canonicalization algorithm.
      </dd>
      <dt>Space-efficient verification of the contents of Datasets</dt>
      <dd>
If unique identification of RDF Datasets is possible, one can cryptographically
hash the information to establish a storage-efficient way to verify that the
information has not changed over time. One property of cryptographic digests is
that one can verify data integrity. For example, a small device sending an RDF
Dataset to a remote storage location can compute a cryptographic digest for
later use in verifying that all the data arrived intact and has not been
tampered with. Requirement: An RDF Dataset Canonicalization algorithm whose
output can be used as input a cryptographic digest function.
      </dd>
      <dt>Secret confirmation of the contents of Datasets</dt>
      <dd>
Since a cryptographic digest is a one-way function, and serves as an
abbreviation for the entire RDF Dataset, one can use it in places where secrecy
is desired. For example, when ensuring that the transaction history on a
distributed ledger is the same between two services, two systems could keep
track of the list of transactions in their respective ledgers. Canonicalizing
and cryptographically hashing the list of transactions should result in the same
cryptographic hash without either party needing to share the list of
transactions with the other. Requirement: An RDF Dataset Canonicalization
algorithm whose cryptographic digest can be shared to establish the unique
identity of the RDF Dataset.
      </dd>
      <dt>
Annotating Datasets with digital signatures and other digital proofs
      </dt>
      <dd>
When publishing or transmitting an RDF Dataset, clearly articulating the entity
that asserted the data and protecting it from undetected modification is useful
for mission critical systems. For example, understanding the issuer of a
Verifiable Credential and ensuring that it is evident when a Verifiable
Presentation has been tampered with underlies the trustworthiness of the encoded
information. Requirement: A way of encoding and verifying a digital signature on
an RDF Dataset.
      </dd>
    </dl>
  </section>
</body>

</html>
